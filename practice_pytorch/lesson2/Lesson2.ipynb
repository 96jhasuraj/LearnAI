{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2cb9c66-5209-46b0-8432-dd337966a4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n1. use torch.tensor() not Tensor() -> alias for FloatTensor()\\n2. example : w = torch.empty((100,200), dtype=torch.float64, device=\"cuda\")\\n3. castinf : x2.to(torch.float64)\\n4. view() is preferred over reshape() : Use view() instead to ensure the tensor is not copied.\\n5. torch.squeeze(), torch.unsqueeze()\\n6. use of dim : torch.mean(x,1) will compute the mean for each row\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "1. use torch.tensor() not Tensor() -> alias for FloatTensor()\n",
    "2. example : w = torch.empty((100,200), dtype=torch.float64, device=\"cuda\")\n",
    "3. castinf : x2.to(torch.float64)\n",
    "4. view() is preferred over reshape() : Use view() instead to ensure the tensor is not copied.\n",
    "5. torch.squeeze(), torch.unsqueeze()\n",
    "6. use of dim : torch.mean(x,1) will compute the mean for each row\n",
    "7. graph is recreated from scratch; after each .backward() call, autograd starts populating a new graph. This is exactly what allows you to use control flow statements in your model; you can change the shape, size and operations at every iteration if needed.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7c6091a-dba0-49b3-bda9-b637030b7a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea49876f-0811-41fc-b493-3ce7cb1a086a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2823626428896,             0],\n",
       "         [            0,             0]]),\n",
       " tensor([[1, 1],\n",
       "         [1, 1]]),\n",
       " tensor([[0, 0],\n",
       "         [0, 0]]),\n",
       " tensor([[4, 3],\n",
       "         [1, 6]]),\n",
       " tensor([[10, 10],\n",
       "         [10, 10]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.randint(0,10,(2,2))\n",
    "torch.empty_like(w) , torch.ones_like(w) , torch.zeros_like(w) , w , torch.full(w.size(),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "289e9f89-268f-4d54-a982-d7790a061c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(w,'w.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7683e52f-5de2-4cbd-86f6-bab5198dab7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 3],\n",
      "        [1, 6]])\n"
     ]
    }
   ],
   "source": [
    "x2 = torch.load('w.pkl')\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c155a2ec-30c5-45f6-87d9-d06aec615896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.int64, device(type='cpu'), torch.Size([2, 2]), 2, None, torch.strided)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.dtype , x2.device , x2.shape , x2.ndim , x2.grad , x2.layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88c12e3c-fb13-4401-b885-fb9a384f5126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 3.],\n",
       "        [1., 6.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.to(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ca90f03-bd2c-450a-a51a-26ead543a0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1105, 0.3492],\n",
       "        [0.4588, 0.4326]], dtype=torch.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand_like(x2.to(torch.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b564fcad-8742-48cf-b31e-6d29c3739e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3, 6]),\n",
       " tensor([1]),\n",
       " tensor([[4, 1],\n",
       "         [3, 6]]),\n",
       " tensor([[4],\n",
       "         [3],\n",
       "         [1],\n",
       "         [6]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2[:,1] , x2[x2<3] , x2.t() , x2.view(4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ab16828-12d1-432b-824c-837f8c921b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[4, 3, 1, 6]],\n",
      "\n",
      "        [[4, 3, 1, 6]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, torch.Size([2, 1, 4]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.stack((x2.view(1,4), x2.view(1,4)))\n",
    "print(y) , y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c165d4b-73bd-489e-a90b-bc944b9417f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4, 3],\n",
       "         [1, 6],\n",
       "         [4, 3],\n",
       "         [1, 6]]),\n",
       " torch.Size([4, 2]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((x2,x2)),torch.cat((x2,x2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "078e9a22-5dae-4e0a-af3e-ef239d16c87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4, 3],\n",
       "         [1, 6],\n",
       "         [4, 3],\n",
       "         [1, 6]]),\n",
       " tensor([[4, 3, 4, 3],\n",
       "         [1, 6, 1, 6]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((x2,x2),dim=0) , torch.cat((x2,x2),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f97bf6e-b4d5-4742-a1ca-b42785d30d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae188e6e-d0ad-4053-9bca-50f34a421277",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1,2,3],[4,5,6]],\n",
    "         dtype=torch.float, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9570ac7-a598-4471-ab44-2ac9419d95c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = x.pow(2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d1bd996-00fa-4a88-9a5f-8b5bef1fabfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(91., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94c63880-afbc-4b9e-965c-b9a297c885b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.,  4.,  6.],\n",
       "        [ 8., 10., 12.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "947102fd-0b92-40f2-8581-eeaee8d6f179",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([2., 3.], requires_grad=True)\n",
    "b = torch.tensor([6., 4.], requires_grad=True)\n",
    "Q = 3*a**3 - b**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44736175-da4c-4646-9161-41b9c9da729b",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_grad = torch.tensor([1., 1.])\n",
    "Q.backward(gradient=external_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b74da9e-e53b-4319-99c1-fd0aac29dd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True]) tensor([36., 81.])\n",
      "tensor([True, True]) tensor([-12.,  -8.])\n"
     ]
    }
   ],
   "source": [
    "print(9*a**2 == a.grad,a.grad)\n",
    "print(-2*b == b.grad,b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac085eea-02cb-4748-b37f-1f5a5f97acd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mSignature:\u001b[39m\n",
       "Q.backward(\n",
       "    gradient=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "    retain_graph=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "    create_graph=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
       "    inputs=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
       ")\n",
       "\u001b[31mDocstring:\u001b[39m\n",
       "Computes the gradient of current tensor wrt graph leaves.\n",
       "\n",
       "The graph is differentiated using the chain rule. If the tensor is\n",
       "non-scalar (i.e. its data has more than one element) and requires\n",
       "gradient, the function additionally requires specifying a ``gradient``.\n",
       "It should be a tensor of matching type and shape, that represents\n",
       "the gradient of the differentiated function w.r.t. ``self``.\n",
       "\n",
       "This function accumulates gradients in the leaves - you might need to zero\n",
       "``.grad`` attributes or set them to ``None`` before calling it.\n",
       "See :ref:`Default gradient layouts<default-grad-layouts>`\n",
       "for details on the memory layout of accumulated gradients.\n",
       "\n",
       ".. note::\n",
       "\n",
       "    If you run any forward ops, create ``gradient``, and/or call ``backward``\n",
       "    in a user-specified CUDA stream context, see\n",
       "    :ref:`Stream semantics of backward passes<bwd-cuda-stream-semantics>`.\n",
       "\n",
       ".. note::\n",
       "\n",
       "    When ``inputs`` are provided and a given input is not a leaf,\n",
       "    the current implementation will call its grad_fn (though it is not strictly needed to get this gradients).\n",
       "    It is an implementation detail on which the user should not rely.\n",
       "    See https://github.com/pytorch/pytorch/pull/60521#issuecomment-867061780 for more details.\n",
       "\n",
       "Args:\n",
       "    gradient (Tensor, optional): The gradient of the function\n",
       "        being differentiated w.r.t. ``self``.\n",
       "        This argument can be omitted if ``self`` is a scalar.\n",
       "    retain_graph (bool, optional): If ``False``, the graph used to compute\n",
       "        the grads will be freed. Note that in nearly all cases setting\n",
       "        this option to True is not needed and often can be worked around\n",
       "        in a much more efficient way. Defaults to the value of\n",
       "        ``create_graph``.\n",
       "    create_graph (bool, optional): If ``True``, graph of the derivative will\n",
       "        be constructed, allowing to compute higher order derivative\n",
       "        products. Defaults to ``False``.\n",
       "    inputs (sequence of Tensor, optional): Inputs w.r.t. which the gradient will be\n",
       "        accumulated into ``.grad``. All other tensors will be ignored. If not\n",
       "        provided, the gradient is accumulated into all the leaf Tensors that were\n",
       "        used to compute the :attr:`tensors`.\n",
       "\u001b[31mFile:\u001b[39m      d:\\code\\ml\\git_repo_for_ml_learning\\python_envs\\pytch\\lib\\site-packages\\torch\\_tensor.py\n",
       "\u001b[31mType:\u001b[39m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Q.backward?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54106f10-7a95-4467-a4c6-561cee0ff499",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freezing Layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2afe7250-52a8-4345-bba0-91a9a3b2c0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\Suraj/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 44.7M/44.7M [00:12<00:00, 3.82MB/s]\n"
     ]
    }
   ],
   "source": [
    "from torch import nn, optim\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "\n",
    "# Freeze all the parameters in the network\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6790afc7-c766-42c5-8b27-f99bd327d63b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6e3c93d-920e-41e7-b48a-ff1913090982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autograd\n",
    "# https://docs.pytorch.org/docs/stable/notes/autograd.html\n",
    "# https://docs.pytorch.org/docs/stable/notes/extending.html\n",
    "'''\n",
    "DAG with leaves as inputs & roots as o/ps \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "877906bb-2cb5-4857-ba5e-3c60d278bd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor(2.0,requires_grad=True)\n",
    "b = torch.tensor(3.0)\n",
    "c = a*b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b535c249-7fa3-456c-9d91-5cb171903485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2., requires_grad=True),\n",
       " tensor(3.),\n",
       " tensor(6., grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "663f1a2f-c6bf-42c7-9642-8d05631f4a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mCall signature:\u001b[39m c.grad_fn(*args, **kwargs)\n",
       "\u001b[31mType:\u001b[39m           MulBackward0\n",
       "\u001b[31mString form:\u001b[39m    <MulBackward0 object at 0x0000022349024CD0>\n",
       "\u001b[31mDocstring:\u001b[39m      <no docstring>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c.grad_fn??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0dbbc95d-f4cf-4380-8794-c938020284d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(5, requires_grad=True)\n",
    "y = x.pow(2)\n",
    "print(x.equal(y.grad_fn._saved_self))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d7c191a-3fb7-4217-b058-345937e19c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.5059,  0.7238, -0.8231, -0.2720,  0.6299], requires_grad=True),\n",
       " tensor([0.2560, 0.5238, 0.6776, 0.0740, 0.3968], grad_fn=<PowBackward0>),\n",
       " tensor([ 0.5059,  0.7238, -0.8231, -0.2720,  0.6299], requires_grad=True))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y,y.grad_fn._saved_self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2e65d8ba-c576-471c-a34c-e10ac284fb72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nautograd example \\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "autograd example \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2833092e-f0cd-4ea1-a7d5-cadbd6351809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import List, NamedTuple, Callable, Dict, Optional\n",
    "\n",
    "_name: int = 0\n",
    "def fresh_name() -> str:\n",
    "    \"\"\" create a new unique name for a variable: v0, v1, v2 \"\"\"\n",
    "    global _name\n",
    "    r = f'v{_name}'\n",
    "    _name += 1\n",
    "    return r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8c098633-d29a-4b86-9440-92b509a94eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Variable:\n",
    "    def __init__(self, value : torch.Tensor, name: str=None):\n",
    "        self.value = value\n",
    "        self.name = name or fresh_name() \n",
    "    @staticmethod\n",
    "    def constant(value: torch.Tensor, name: str=None):\n",
    "        r = Variable(value, name)\n",
    "        print(f'{r.name} = {value}')\n",
    "        return r\n",
    "    def __repr__(self):\n",
    "        return repr(self.value)\n",
    "    def __mul__(self, rhs: 'Variable') -> 'Variable':\n",
    "        return operator_mul(self, rhs)\n",
    "\n",
    "    def __add__(self, rhs: 'Variable') -> 'Variable':\n",
    "        return operator_add(self, rhs)\n",
    "            \n",
    "    def sum(self, name: Optional[str]=None) -> 'Variable':\n",
    "        return operator_sum(self, name)\n",
    "    \n",
    "    def expand(self, sizes: List[int]) -> 'Variable':\n",
    "        return operator_expand(self, sizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "480ad300-012c-45f4-9b10-38bc43ee0bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TapeEntry(NamedTuple):\n",
    "    # names of the inputs to the original computation\n",
    "    inputs : List[str]\n",
    "    # names of the outputs of the original computation\n",
    "    outputs: List[str]\n",
    "    # apply chain rule\n",
    "    propagate: 'Callable[List[Variable], List[Variable]]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f6afadc8-db87-4f9a-b536-6015519f29ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_tape : List[TapeEntry] = []\n",
    "\n",
    "def reset_tape():\n",
    "  gradient_tape.clear()\n",
    "  global _name\n",
    "  _name = 0 # reset variable names too to keep them small.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f75f9880-9755-4a80-9c14-b827a20c181a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def operator_mul(self : Variable, rhs: Variable) -> Variable:\n",
    "    if isinstance(rhs, float) and rhs == 1.0:\n",
    "        # peephole optimization\n",
    "        return self\n",
    "\n",
    "    # define forward\n",
    "    r = Variable(self.value * rhs.value)\n",
    "    print(f'{r.name} = {self.name} * {rhs.name}')\n",
    "\n",
    "    # record what the inputs and outputs of the op were\n",
    "    inputs = [self.name, rhs.name]\n",
    "    outputs = [r.name]\n",
    "\n",
    "    # define backprop\n",
    "    def propagate(dL_doutputs: List[Variable]):\n",
    "        dL_dr, = dL_doutputs\n",
    "    \n",
    "        dr_dself = rhs # partial derivative of r = self*rhs\n",
    "        dr_drhs = self # partial derivative of r = self*rhs\n",
    "\n",
    "        # chain rule propagation from outputs to inputs of multiply\n",
    "        dL_dself = dL_dr * dr_dself\n",
    "        dL_drhs = dL_dr * dr_drhs\n",
    "        dL_dinputs = [dL_dself, dL_drhs] \n",
    "        return dL_dinputs\n",
    "    # finally, we record the compute we did on the tape\n",
    "    gradient_tape.append(TapeEntry(inputs=inputs, outputs=outputs, propagate=propagate))\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cee0abb9-12d9-4096-8c90-ac6bc14c3d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(L, desired_results: List[Variable]) -> List[Variable]:\n",
    "    # this map holds dL/dX for all values X\n",
    "    dL_d : Dict[str, Variable] = {}\n",
    "    # It starts by initializing the 'seed' dL/dL, which is 1\n",
    "    dL_d[L.name] = Variable(torch.ones(()))\n",
    "    print(f'd{L.name} ------------------------')\n",
    "\n",
    "    # look up dL_dentries. If a variable is never used to compute the loss,\n",
    "    # we consider its gradient None, see the note below about zeros for more information.\n",
    "    def gather_grad(entries: List[str]):\n",
    "        return [dL_d[entry] if entry in dL_d else None for entry in entries]\n",
    "\n",
    "    # propagate the gradient information backward\n",
    "    for entry in reversed(gradient_tape):\n",
    "        dL_doutputs = gather_grad(entry.outputs)\n",
    "        if all(dL_doutput is None for dL_doutput in dL_doutputs):\n",
    "            # optimize for the case where some gradient pathways are zero. See\n",
    "            # The note below for more details.\n",
    "            continue\n",
    "\n",
    "        # perform chain rule propagation specific to each compute\n",
    "        dL_dinputs = entry.propagate(dL_doutputs)\n",
    "\n",
    "        # Accululate the gradient produced for each input.\n",
    "        # Each use of a variable produces some gradient dL_dinput for that \n",
    "        # use. The multivariate chain rule tells us it is safe to sum \n",
    "        # all the contributions together.\n",
    "        for input, dL_dinput in zip(entry.inputs, dL_dinputs):\n",
    "            if input not in dL_d:\n",
    "                dL_d[input] = dL_dinput\n",
    "            else:\n",
    "                dL_d[input] += dL_dinput\n",
    "\n",
    "    # print some information to understand the values of each intermediate \n",
    "    for name, value in dL_d.items():\n",
    "        print(f'd{L.name}_d{name} = {value.name}')\n",
    "    print(f'------------------------')\n",
    "\n",
    "    return gather_grad(desired.name for desired in desired_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "48f6cdd9-f759-43bd-82aa-2a0e80a3320b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def operator_add(self : Variable, rhs: Variable) -> Variable:\n",
    "    # Add follows a similar pattern to Mul, but it doesn't end up\n",
    "    # capturing any variables.\n",
    "    r = Variable(self.value + rhs.value)\n",
    "    print(f'{r.name} = {self.name} + {rhs.name}')\n",
    "    def propagate(dL_doutputs: List[Variable]):\n",
    "        dL_dr, = dL_doutputs\n",
    "        dr_dself = 1.0\n",
    "        dr_drhs = 1.0\n",
    "        dL_dself = dL_dr * dr_dself\n",
    "        dL_drhs = dL_dr * dr_drhs\n",
    "        return [dL_dself, dL_drhs]\n",
    "    gradient_tape.append(TapeEntry(inputs=[self.name, rhs.name], outputs=[r.name], propagate=propagate))\n",
    "    return r\n",
    "\n",
    "# sum is used to turn our matrices into a single scalar to get a loss.\n",
    "# expand is the backward of sum, so it is added to make sure our Variable\n",
    "# is closed under differentiation. Both have rules similar to mul above.\n",
    "\n",
    "def operator_sum(self: Variable, name: Optional[str]) -> 'Variable':\n",
    "    r = Variable(torch.sum(self.value), name=name)\n",
    "    print(f'{r.name} = {self.name}.sum()')\n",
    "    def propagate(dL_doutputs: List[Variable]):\n",
    "        dL_dr, = dL_doutputs\n",
    "        size = self.value.size()\n",
    "        return [dL_dr.expand(*size)]\n",
    "    gradient_tape.append(TapeEntry(inputs=[self.name], outputs=[r.name], propagate=propagate))\n",
    "    return r\n",
    "\n",
    "\n",
    "def operator_expand(self: Variable, sizes: List[int]) -> 'Variable':\n",
    "    assert(self.value.dim() == 0) # only works for scalars\n",
    "    r = Variable(self.value.expand(sizes))\n",
    "    print(f'{r.name} = {self.name}.expand({sizes})')\n",
    "    def propagate(dL_doutputs: List[Variable]):\n",
    "        dL_dr, = dL_doutputs\n",
    "        return [dL_dr.sum()]\n",
    "    gradient_tape.append(TapeEntry(inputs=[self.name], outputs=[r.name], propagate=propagate))\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "71f2efa6-82aa-4f9c-8918-25565d535315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = tensor([0.7680, 0.5106, 0.1505, 0.9638])\n",
      "b = tensor([0.2539, 0.0201, 0.4764, 0.6176])\n",
      "v0 = a + b\n",
      "v1 = v0 * b\n",
      "dv1 ------------------------\n",
      "v3 = v2 * b\n",
      "v4 = v2 * v0\n",
      "v5 = v4 + v3\n",
      "dv1_dv1 = v2\n",
      "dv1_dv0 = v3\n",
      "dv1_db = v5\n",
      "dv1_da = v3\n",
      "------------------------\n",
      "da tensor([0.2539, 0.0201, 0.4764, 0.6176])\n",
      "db tensor([1.2759, 0.5508, 1.1032, 2.1990])\n"
     ]
    }
   ],
   "source": [
    "a_global, b_global = torch.rand(4), torch.rand(4)\n",
    "\n",
    "def simple(a, b):\n",
    "    t = a + b\n",
    "    return t * b\n",
    "\n",
    "reset_tape() # reset any compute from other cells\n",
    "a = Variable.constant(a_global, name='a')\n",
    "b = Variable.constant(b_global, name='b')\n",
    "loss = simple(a, b)\n",
    "da, db = grad(loss, [a, b])\n",
    "print(\"da\", da)\n",
    "print(\"db\", db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aed1d9-f982-4f36-ad92-49ef574708f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
