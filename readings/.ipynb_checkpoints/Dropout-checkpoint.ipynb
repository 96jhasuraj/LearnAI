{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3209346c-8e54-4ddc-bfbe-37568092d88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torchvision.transforms as tvtransforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f02adc6-b21a-459a-9199-8570ab97e25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7192e178-b2f9-4771-8193-042d2ca44bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_lr = 2.0\n",
    "lr_decay = 0.995\n",
    "initial_momentum = 0.5\n",
    "final_momentum = 0.99\n",
    "momentum_epochs = 25\n",
    "max_norm = 15.0 \n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "dropout_hidden = 0.5\n",
    "dropout_input = 0.2\n",
    "weight_std = 0.01\n",
    "# paper trains models for 3000 epochs . Init Lr is 10 . Init decay is 0.998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5beebd2-f84e-4e0c-8c6a-f45aa091f87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated mean: 0.1307, std: 0.3081\n"
     ]
    }
   ],
   "source": [
    "raw_transform = tvtransforms.ToTensor()\n",
    "raw_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=raw_transform)\n",
    "\n",
    "# Compute mean and std\n",
    "loader = DataLoader(raw_dataset, batch_size=60000, shuffle=False)\n",
    "data_iter = iter(loader)\n",
    "images, _ = next(data_iter)\n",
    "mean = images.mean().item()\n",
    "std = images.std().item()\n",
    "\n",
    "print(f\"Calculated mean: {mean:.4f}, std: {std:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95cc9958-fba4-41b5-bac0-4b20f8ddcb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_transform = tvtransforms.Compose([\n",
    "    tvtransforms.RandomRotation(10),\n",
    "    tvtransforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
    "    tvtransforms.ToTensor(), \n",
    "    tvtransforms.Normalize((mean,), (std,)),\n",
    "])\n",
    "\n",
    "mnist_test_transform = tvtransforms.Compose([\n",
    "    tvtransforms.ToTensor(), \n",
    "    tvtransforms.Normalize((mean,), (std,)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb1944d4-3d06-45e5-ac55-043193b2500c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=mnist_train_transform)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=mnist_test_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42ba2000-6b75-4739-8981-a4218e5ff18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def constrain_weights(module):\n",
    "    for name, param in module.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            l2_norms = torch.sqrt(torch.sum(param**2, dim=1, keepdim=True))\n",
    "            scale = torch.clamp(torch.sqrt(torch.tensor(max_norm)) / (l2_norms + 1e-12), max=1.0)\n",
    "            param.data *= scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57232a67-2943-45e3-8da1-74cfac94e961",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, layer_sizes):\n",
    "        super(NN, self).__init__()\n",
    "        layers = []\n",
    "        layers.append(nn.Dropout(p=dropout_input))\n",
    "        for i in range(len(layer_sizes) - 2):\n",
    "            layers.append(nn.Linear(layer_sizes[i], layer_sizes[i+1]))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(p=dropout_hidden))\n",
    "        layers.append(nn.Linear(layer_sizes[-2], layer_sizes[-1]))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, mean=0, std=weight_std)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f59b8e0-a4b9-46cc-a5de-c547961ac2ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'params': [Parameter containing:\n",
       "   tensor([[ 0.1040,  0.1035,  0.0895,  ...,  0.1009,  0.1057,  0.0579],\n",
       "           [ 0.0844,  0.1095,  0.0458,  ...,  0.1174,  0.0999,  0.0887],\n",
       "           [ 0.1128,  0.1369,  0.0931,  ...,  0.1249,  0.1267,  0.1115],\n",
       "           ...,\n",
       "           [ 0.0590,  0.1164,  0.1133,  ...,  0.1151,  0.1109,  0.1067],\n",
       "           [ 0.0938,  0.0785,  0.0884,  ...,  0.0995,  0.0953,  0.0832],\n",
       "           [ 0.0080,  0.0214,  0.0067,  ...,  0.0145, -0.0018,  0.0200]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-2.3552e+00, -1.0232e+00, -4.8118e-01, -1.5628e-02, -1.0500e+00,\n",
       "           -2.8960e-02, -9.6269e-02, -3.2522e-02, -1.2067e-01, -8.6805e-01,\n",
       "           -4.8060e-01, -2.3608e-02, -3.8649e-01, -3.0125e-02, -2.7715e-02,\n",
       "           -5.5203e+00, -8.8175e-02, -5.4638e-02, -1.8469e-02, -9.0133e-02,\n",
       "           -2.0483e-01, -1.5325e-02, -1.1343e+00, -4.2654e+00, -1.6197e-02,\n",
       "           -4.3128e-01, -1.4309e-01, -1.1287e+01, -1.3046e-01, -1.3557e-02,\n",
       "           -2.6248e-01, -5.1946e+00, -2.9062e-01, -2.7788e+00, -5.4853e-02,\n",
       "           -4.8640e-02, -1.7155e+00, -3.2134e-01, -2.6164e-02, -1.7327e-01,\n",
       "           -1.6504e-02, -1.6751e-02, -1.3700e-02, -1.3762e-02, -1.1436e+00,\n",
       "           -3.8714e-01, -1.6430e-02, -5.4498e+00, -9.7480e+00, -1.0141e+00,\n",
       "           -6.9320e-03, -2.7825e-01, -7.8792e-01, -2.1784e-02, -1.6831e-01,\n",
       "           -1.8688e-02, -3.5245e+00, -5.3415e-01, -4.2380e-02, -1.0972e+01,\n",
       "           -6.8880e-02, -8.9682e-01, -2.4748e+00, -3.6435e-02, -1.0256e+00,\n",
       "           -1.7674e-02, -4.7887e+00, -6.9429e+00, -9.6710e-01, -1.3365e+01,\n",
       "           -3.0851e-02, -8.0816e-01, -3.5403e-02, -2.9127e-02, -5.4712e-02,\n",
       "           -2.3371e-01, -2.3844e-02, -7.3994e-02, -3.6284e-02, -7.1267e-01,\n",
       "           -1.5979e-02, -1.0799e+00, -2.2771e-02, -1.7783e+00, -2.7082e-02,\n",
       "           -3.7357e-02, -2.3055e-01, -9.0747e-03, -1.0708e+00, -1.8540e-01,\n",
       "           -1.7464e-02, -2.1697e-01, -5.8499e-02, -2.8177e-01, -2.4970e-02,\n",
       "           -1.9655e+00, -2.2815e+00, -1.4074e-02, -5.0817e-01, -1.0086e-01,\n",
       "           -1.5191e-01, -4.9751e-01, -2.5604e+00, -4.3544e-02, -3.5502e-02,\n",
       "           -8.1183e-02, -2.6369e-02, -2.0132e+00, -3.5353e-02, -3.6364e-02,\n",
       "           -2.8814e+00, -1.2346e+00, -2.9370e-02, -5.3826e-01, -1.1799e-02,\n",
       "           -2.7337e+00, -3.9028e-02, -2.0688e+00, -4.7239e-02, -5.2246e+00,\n",
       "           -1.3631e-02, -8.7282e-01, -7.8234e-02, -4.0231e+00, -7.8837e-02,\n",
       "           -1.4201e-01, -3.1960e-02, -7.0621e-02, -4.1493e-01, -9.4026e-01,\n",
       "           -1.4459e-02, -3.5702e-02, -1.1495e+00, -1.4524e+00, -4.3869e+00,\n",
       "           -2.3019e-02, -4.9688e-01, -9.0316e-02, -4.0481e-02, -2.7759e+00,\n",
       "           -7.1892e-01, -2.9299e-02, -2.3782e-02, -8.0034e-01, -4.3227e-01,\n",
       "           -2.8831e+00, -1.9851e-01, -1.1245e+00, -1.1579e+00, -1.1339e-02,\n",
       "           -1.9776e-02, -1.0661e+01, -4.0306e-02, -2.8858e-02, -5.2680e-02,\n",
       "           -2.4394e-01, -5.6120e-01, -2.8157e-02, -1.1401e-01, -1.2764e-01,\n",
       "           -2.5731e-02, -4.3778e-01, -2.2205e+00, -1.6072e-02, -6.2110e-02,\n",
       "           -2.2778e+00, -1.7141e-02, -5.1565e-01, -1.2365e+00, -1.5961e-01,\n",
       "           -2.3925e-02, -1.1217e-01, -5.2869e-01, -2.0974e-02, -3.3564e-02,\n",
       "           -3.1614e-02, -4.4392e-02, -1.6208e-02, -3.0820e-02, -2.0296e+00,\n",
       "           -2.1667e-02, -1.0464e-01, -1.4309e-01, -2.4035e-02, -1.5894e-02,\n",
       "           -3.2603e-02, -1.2774e-02, -2.5656e-02, -7.7721e-01, -5.6430e-01,\n",
       "           -3.5498e+00, -8.5451e-02, -1.4417e+00, -3.3757e+00, -2.4052e-02,\n",
       "           -1.3768e-01, -2.1907e-02, -2.9129e-02, -3.8758e-01, -2.9895e-02,\n",
       "           -2.8221e-02, -4.7160e-02, -4.7153e-02, -2.5698e-01, -4.1637e-01,\n",
       "           -1.4443e-01, -4.6026e-02, -4.8334e-02, -9.6219e+00, -5.0971e+00,\n",
       "           -7.3849e-03, -2.5923e-01, -5.2388e-02, -4.4974e-02, -8.2483e-01,\n",
       "           -1.7374e-02, -1.0733e-01, -6.9269e-02, -5.1863e-02, -5.0261e-01,\n",
       "           -1.4959e-01, -3.9401e-02, -2.2350e-02, -1.5905e+00, -2.9861e-02,\n",
       "           -4.2032e-02, -2.4482e-02, -2.1116e-02, -1.8688e+00, -7.4180e+00,\n",
       "           -6.5498e-01, -2.2746e-02, -4.5350e-01, -1.8032e-02, -9.0245e-01,\n",
       "           -2.2131e-02, -4.3542e-01, -2.0018e+00, -1.9959e-01, -3.1378e-02,\n",
       "           -1.0548e-02, -4.6223e-01, -3.2459e-02, -6.4571e-02, -4.0962e-02,\n",
       "           -3.2825e-02, -4.9301e+00, -1.2307e+00, -2.0945e-02, -4.0466e+00,\n",
       "           -1.4306e+00, -3.1956e-01, -1.4454e+00, -1.2991e+00, -1.2049e-02,\n",
       "           -2.9620e-02, -2.7241e-02, -1.0879e+00, -1.7071e-02, -1.4657e-02,\n",
       "           -3.3330e-02, -4.7212e-01, -2.6544e-02, -3.6512e-01, -2.7872e-01,\n",
       "           -1.5410e-02, -2.4700e-02, -7.5115e-02, -1.3882e-01, -1.1174e+00,\n",
       "           -2.5600e-02, -1.2856e+00, -2.7291e-01, -4.8024e+00, -3.6477e-01,\n",
       "           -1.1498e-02, -2.1785e-02, -1.4011e+00, -7.8634e-01, -1.0193e-01,\n",
       "           -9.0765e-02, -1.4137e-02, -1.9612e-01, -6.7162e-01, -6.3938e-01,\n",
       "           -4.6775e-01, -3.5919e-02, -9.7273e-01, -1.3526e-02, -4.0917e-01,\n",
       "           -1.0693e+00, -4.3196e-02, -5.1769e-02, -2.9665e-02, -2.5108e-02,\n",
       "           -3.5215e-01, -3.7187e-02, -1.0800e+00, -1.3664e-02, -5.6449e-01,\n",
       "           -7.9900e-01, -2.0584e+01, -2.7343e-02, -3.3445e-02, -1.5918e+00,\n",
       "           -1.3525e-02, -3.6914e-02, -1.9426e-02, -2.9199e-01, -8.8077e-02,\n",
       "           -5.4450e-02, -2.7349e-02, -3.8398e-01, -2.2339e-02, -1.0007e+01,\n",
       "           -4.8511e-02, -1.3569e+00, -1.7416e-02, -7.4288e+00, -1.8252e+00,\n",
       "           -1.8243e-02, -9.8417e-02, -1.5133e-02, -1.1048e-01, -3.8309e-02,\n",
       "           -4.3925e-02, -5.7774e-01, -1.9599e-02, -1.3795e+00, -1.9030e-02,\n",
       "           -6.8444e+00, -2.9795e-02, -1.3851e-02, -1.2286e-02, -7.2296e-02,\n",
       "           -2.5062e-01, -9.6861e-02, -2.4956e-01, -2.4263e-02, -5.0638e-02,\n",
       "           -3.7863e-01, -7.9317e+00, -2.7273e-01, -2.7553e-02, -7.3935e-02,\n",
       "           -1.3008e+00, -3.2349e-02, -7.3592e-02, -2.2705e-02, -3.6408e-01,\n",
       "           -5.7565e-02, -1.0994e+00, -3.6208e-02, -4.3703e-02, -8.2011e-02,\n",
       "           -4.2703e-02, -8.0980e-02, -7.0710e-02, -7.8996e-02, -1.3705e+00,\n",
       "           -2.6670e-01, -1.4479e+00, -2.4877e-02, -5.8216e-01, -1.9250e+00,\n",
       "           -1.1553e-01, -4.9242e-02, -2.1706e+00, -4.3352e-02, -2.5648e-02,\n",
       "           -2.4376e-02, -1.1477e-02, -2.3740e+00, -4.8853e-02, -3.0849e+00,\n",
       "           -3.3666e-02, -2.1994e-02, -4.8686e+00, -2.0260e-01, -2.2086e-02,\n",
       "           -3.8929e-01, -2.9037e-02, -1.9940e+00, -4.0511e-02, -3.9008e-02,\n",
       "           -5.9341e+00, -4.4232e-01, -1.2000e-02, -9.1560e-01, -2.2570e-02,\n",
       "           -1.1402e-02, -7.4439e-02, -1.4802e-02, -8.0758e-02, -1.5694e-01,\n",
       "           -5.2677e-02, -1.9145e-02, -7.1496e-02, -1.1067e+00, -2.1351e+00,\n",
       "           -2.7306e-01, -2.8377e-01, -4.8914e-02, -2.5905e-02, -1.9795e-02,\n",
       "           -1.9709e-02, -6.9145e+00, -1.8766e-02, -1.7323e+00, -1.3033e-01,\n",
       "           -4.3936e-02, -1.7889e-02, -1.8889e+00, -3.1276e-01, -2.9604e-02,\n",
       "           -4.7253e-01, -1.4346e+00, -1.8527e-01, -3.2214e-02, -4.9910e-02,\n",
       "           -3.8096e-01, -2.1532e-02, -1.1053e-01, -2.9512e-02, -9.4851e-02,\n",
       "           -6.0610e-02, -6.5682e-02, -7.3525e-02, -4.1438e-01, -1.9795e-02,\n",
       "           -2.8950e-02, -2.0705e-01, -1.2820e+00, -7.9192e-01, -3.1665e-01,\n",
       "           -2.2613e-02, -1.9602e-02, -1.6873e-02, -2.6093e-02, -3.6313e-02,\n",
       "           -2.3776e-02, -1.8432e-02, -4.1574e-02, -9.2031e-02, -2.0908e-01,\n",
       "           -1.1578e+00, -9.6340e-01, -1.7702e-01, -1.2037e-02, -4.4418e-01,\n",
       "           -3.1467e-02, -3.5885e-01, -2.4276e-02, -8.3361e-01, -2.6523e-02,\n",
       "           -2.2372e-02, -8.3237e+00, -4.1177e-02, -2.8450e+00, -3.0451e-01,\n",
       "           -2.1533e-02, -2.1541e-01, -1.3150e-02, -8.1846e-02, -2.4197e-01,\n",
       "           -7.4368e-01, -3.3294e-01, -2.0612e+00, -5.7715e-02, -1.1286e-02,\n",
       "           -2.5827e-01, -5.5282e-01, -2.8081e-02, -1.8211e+00, -1.1531e-02,\n",
       "           -2.8929e-02, -5.1609e-02, -3.9156e-02, -2.0550e-01, -7.5655e-01,\n",
       "           -4.5414e-02, -2.4528e-02, -4.5381e-01, -3.7708e-01, -6.3347e-01,\n",
       "           -9.8245e-02, -2.6793e-02, -1.8540e-02, -5.6499e-02, -1.9819e-02,\n",
       "           -8.3314e-01, -1.6019e-02, -2.2412e+00, -3.6047e+00, -3.1433e-02,\n",
       "           -1.8076e-01, -1.6175e+00, -1.4383e-01, -3.5625e-02, -8.8309e-02,\n",
       "           -1.9542e-02, -1.3582e+00, -1.1923e-01, -8.5665e-02, -7.9655e-01,\n",
       "           -2.6409e-02, -3.5988e-02, -2.0425e-02, -4.2422e-02, -1.6000e-02,\n",
       "           -3.0162e-02, -1.7571e-01, -3.0582e-02, -2.5301e-01, -5.1102e-02,\n",
       "           -1.4074e-01, -2.1047e-02, -8.5914e-02, -2.2394e+00, -1.7120e-01,\n",
       "           -1.1931e+00, -3.0591e-02, -2.9813e-02, -3.4690e-02, -1.6660e-02,\n",
       "           -5.7087e-01, -1.2719e+01, -1.4120e-01, -2.3794e-02, -4.6400e-02,\n",
       "           -3.1043e-02, -9.7242e-03, -2.9891e-02, -1.9587e-02, -5.3443e-02,\n",
       "           -2.8520e-02, -5.0939e-02, -6.5293e-01, -1.8791e-02, -3.2169e-01,\n",
       "           -1.8682e+00, -1.6844e+00, -6.6824e-01, -4.9247e-02, -3.5216e-01,\n",
       "           -5.3885e+00, -5.3998e-01, -1.4191e-02, -7.2195e-02, -1.0126e+00,\n",
       "           -2.0780e-01, -5.7908e-01, -2.6296e+00, -2.3038e-02, -5.0741e-02,\n",
       "           -2.1001e-02, -1.4251e-02, -7.9848e-02, -7.0046e-02, -5.2647e-02,\n",
       "           -2.2172e-02, -7.0252e-02, -3.4255e-02, -2.3969e-02, -1.6735e-01,\n",
       "           -7.0708e-01, -9.3427e-01, -4.3005e-02, -5.9046e-02, -1.8404e-01,\n",
       "           -4.0607e-01, -4.7530e-01, -2.0022e-01, -5.3008e-01, -1.3987e-02,\n",
       "           -2.2221e-02, -1.1670e-02, -1.9902e-02, -2.7757e-02, -9.0429e-01,\n",
       "           -2.1517e-02, -2.1668e-01, -3.1024e-01, -2.3503e-01, -8.4752e-01,\n",
       "           -1.5336e-02, -9.6158e-01, -1.1237e-02, -1.0664e+00, -3.5079e-01,\n",
       "           -2.5062e-02, -3.8194e-01, -7.5497e-01, -2.3263e-01, -2.4721e+00,\n",
       "           -7.3372e-02, -2.5522e-01, -3.3060e-02, -5.3329e-01, -2.6827e-01,\n",
       "           -1.0156e-02, -2.6641e-01, -2.8790e-01, -1.3040e+00, -1.8514e-01,\n",
       "           -1.5080e+00, -5.7517e-02, -6.8558e-02, -9.8359e-02, -1.4846e-02,\n",
       "           -2.6129e-02, -2.3506e-02, -3.7513e-01, -4.1359e-01, -4.5311e-01,\n",
       "           -4.7822e-02, -3.5958e-01, -2.2421e-02, -2.5172e-02, -1.7468e-01,\n",
       "           -2.2137e-02, -3.8685e-02, -9.9478e-02, -2.7291e-02, -2.7303e-01,\n",
       "           -4.6407e-02, -1.0734e+00, -7.6030e-03, -9.2998e-01, -9.4616e-01,\n",
       "           -8.4666e-01, -1.7550e-02, -2.4334e-01, -4.0057e-02, -3.5253e-02,\n",
       "           -8.8100e-02, -1.6193e-02, -1.8436e-02, -8.3919e-01, -2.7821e-01,\n",
       "           -1.8516e-02, -2.7301e-01, -3.1130e-02, -4.0316e-01, -1.3962e+00,\n",
       "           -2.1715e-01, -5.6707e-02, -5.4454e-02, -1.5821e-01, -6.5226e-02,\n",
       "           -9.8499e-01, -5.3442e-01, -3.9153e-01, -1.6535e-02, -2.8196e-02,\n",
       "           -3.2678e-02, -3.0753e-02, -5.8093e-02, -1.3654e+00, -3.8913e-01,\n",
       "           -4.2336e-02, -5.8278e-01, -1.4694e+00, -5.5698e-01, -2.0564e-01,\n",
       "           -1.6523e-02, -1.1097e+00, -2.4103e-01, -4.2841e-02, -4.1888e+00,\n",
       "           -4.7271e-02, -3.8577e-02, -2.5041e+00, -1.3131e-01, -2.4647e+00,\n",
       "           -1.1925e+00, -3.0180e-02, -7.7170e+00, -1.5461e-02, -4.5520e-02,\n",
       "           -7.3720e-02, -5.7808e-02, -1.6004e+00, -1.4244e-02, -1.5581e-02,\n",
       "           -1.5330e-01, -2.0731e-01, -2.2732e-02, -1.5362e+00, -1.3173e+00,\n",
       "           -1.0748e+00, -9.8839e+00, -5.6098e-01, -1.5007e-02, -6.1742e-02,\n",
       "           -9.1202e-02, -4.5711e+00, -1.8038e-02, -5.3492e+00, -1.2408e-01,\n",
       "           -1.6368e-02, -3.0404e-01, -1.3185e+00, -1.6885e-02, -2.6643e-01,\n",
       "           -1.0362e+00, -3.8012e-01, -9.7471e-01, -3.8100e-01, -3.8808e-01,\n",
       "           -4.3863e-02, -3.1305e-02, -1.9676e+00, -3.4264e-02, -4.3613e-01,\n",
       "           -1.8349e+00, -3.7935e-02, -3.4059e-02, -4.7297e-02, -4.1330e-02,\n",
       "           -5.1621e+00, -2.0828e+00, -2.9637e-01, -2.5829e-02, -1.5379e-01,\n",
       "           -1.8971e+00, -3.7613e-02, -2.4559e-02, -7.3329e-02, -4.2722e-02,\n",
       "           -6.0093e+00, -1.0092e-02, -9.3727e-01, -9.1449e-01, -1.7116e-02,\n",
       "           -2.4651e-02, -1.5121e-02, -4.9150e-02, -1.0171e-02, -2.4069e+00,\n",
       "           -1.7534e-01, -5.1891e-01, -4.1072e-02, -1.8374e-02, -2.6419e-01,\n",
       "           -1.1731e+00, -5.5861e-02, -4.0498e-02, -2.2138e-02, -2.3063e-01,\n",
       "           -5.1769e-02, -1.0071e-01, -3.5105e-01, -2.1064e-02, -2.4882e-02,\n",
       "           -6.5843e-01, -3.4414e-01, -1.1882e-01, -1.3249e-02, -2.3624e-01,\n",
       "           -1.1063e-01, -1.7888e-01, -1.5175e-02, -2.1631e-02, -1.0727e+00,\n",
       "           -3.0922e-02, -1.1729e+00, -1.2382e-01, -1.5434e-02, -1.2717e+00,\n",
       "           -1.7618e-01, -5.0960e-02, -5.9323e-01, -4.9133e-02, -2.3663e-01,\n",
       "           -4.0476e-02, -8.1931e-02, -2.8361e-02, -2.4529e+00, -5.9965e-01,\n",
       "           -8.7916e+00, -1.1002e-01, -1.1272e+00, -1.6402e-02, -2.8267e-02,\n",
       "           -2.9198e-02, -4.4664e-02, -2.1348e+00, -3.0776e-02, -1.6285e-02,\n",
       "           -7.4745e-02, -3.6274e-02, -5.5299e-02, -5.6360e-02, -4.8272e-02,\n",
       "           -4.1021e-02, -3.2379e-02, -1.0933e+00, -1.2842e+00, -2.5885e-02],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-4.6753e-03,  1.7128e-02, -2.5327e-02,  ...,  3.7852e-03,\n",
       "            -1.9297e-01,  1.3033e-03],\n",
       "           [-4.3880e-02, -3.8067e-03, -1.6530e-02,  ..., -2.9519e-02,\n",
       "            -6.7031e-03, -3.5449e-03],\n",
       "           [ 7.3102e-03,  7.5704e-02,  1.2791e-03,  ..., -3.5099e-04,\n",
       "            -3.6228e-02, -8.7717e-06],\n",
       "           ...,\n",
       "           [-4.0111e-02, -8.0378e-03, -3.5492e-02,  ..., -2.3388e-02,\n",
       "            -9.9148e-03,  4.5679e-03],\n",
       "           [-2.6629e-03, -8.0349e-03, -5.3009e-02,  ..., -1.5551e-01,\n",
       "            -1.6519e-02,  2.0222e-04],\n",
       "           [-9.9810e-02,  3.2691e-04,  1.4262e-04,  ..., -7.8279e-04,\n",
       "            -1.9091e-02,  2.8456e-03]], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-0.6001, -0.7887, -1.2319, -0.1890, -0.7053, -0.7050, -0.4926, -1.6352,\n",
       "           -0.5028, -0.2547, -0.2123, -0.6628, -0.1218, -0.6419, -0.2332, -0.4157,\n",
       "           -0.6047, -0.7040, -1.7159, -0.7278, -0.6715, -0.8832, -0.9588, -0.4697,\n",
       "           -0.2252, -0.7211, -0.1802, -0.4022, -0.4455, -1.0101, -1.0874, -0.4147,\n",
       "           -0.7348, -1.2846, -0.2808, -0.7669, -0.5043, -0.5766, -0.4456, -0.3638,\n",
       "           -0.9313, -0.8718, -0.2629, -1.5298, -0.6603, -0.4377, -0.2308, -0.3649,\n",
       "           -1.1200, -0.7204, -1.4413, -0.5317, -0.1342, -0.6206, -0.8291, -0.2787,\n",
       "           -0.4560, -1.1460, -1.1042, -0.6264, -0.9693, -2.1121, -0.6806, -0.4389,\n",
       "           -0.8731, -0.5579, -0.4622, -0.3389, -0.3156, -1.1554, -0.4012, -4.6621,\n",
       "           -1.0447, -0.5986, -0.2089, -0.6972, -0.4530, -0.4773, -0.3466, -0.8526,\n",
       "           -0.5724, -1.0513, -1.7715, -0.5973, -0.6215, -0.8250, -0.3377, -0.3526,\n",
       "           -0.4477, -0.3471, -1.5945, -1.0077, -1.2545, -0.4008, -0.6585, -0.8764,\n",
       "           -0.6206, -0.7208, -0.3223, -1.2259, -1.1718, -0.5343, -0.5820, -0.4255,\n",
       "           -0.3868, -0.8666, -0.8420, -1.3001, -0.2438, -0.4365, -0.4084, -0.2685,\n",
       "           -0.5376, -0.9166, -0.2947, -1.7101, -0.6733, -0.3116, -1.1727, -1.0828,\n",
       "           -1.4103, -0.2633, -0.6497, -0.4304, -0.6521, -0.1845, -0.1077, -0.3754,\n",
       "           -0.1855, -1.4504, -1.0662, -0.6758, -0.2014, -0.2388, -0.6949, -0.1851,\n",
       "           -1.0290, -0.4494, -0.6819, -0.7488, -0.5882, -0.5348, -0.6790, -0.5109,\n",
       "           -0.5078, -0.2709, -1.6874, -0.6965, -0.7706, -0.5544, -0.5479, -0.7595,\n",
       "           -0.2497, -0.1802, -2.0041, -0.3708, -0.7791, -0.7055, -0.2518, -0.3822,\n",
       "           -0.1290, -1.6826, -0.5975, -0.4034, -0.3590, -1.6936, -0.0914, -0.2578,\n",
       "           -1.0540, -0.5793, -0.1517, -0.1291, -1.7057, -0.6602, -0.2224, -0.2113,\n",
       "           -0.5676, -0.4511, -0.4606, -0.2427, -0.5518, -0.8916, -0.5682, -0.8562,\n",
       "           -0.2498, -0.3423, -0.9729, -0.5609, -3.4372, -1.5907, -0.3929, -0.8877,\n",
       "           -1.2427, -0.5269, -0.4213, -0.2682, -1.5595, -0.4667, -0.7234, -0.4604,\n",
       "           -1.5093, -0.3827, -0.6279, -0.6442, -1.0160, -1.5978, -0.3872, -0.8769,\n",
       "           -0.3932, -1.9470, -0.9354, -0.6467, -0.2129, -0.2163, -1.3667, -1.0264,\n",
       "           -0.2714, -0.4490, -0.9142, -0.5172, -0.9942, -0.4011, -1.6062, -0.2779,\n",
       "           -1.1911, -0.1557, -0.8222, -0.4167, -0.6671, -0.7522, -1.2664, -0.5924,\n",
       "           -0.9647, -0.8572, -0.7328, -1.3037, -0.4791, -0.8242, -0.2610, -0.3167,\n",
       "           -0.8954, -0.5002, -0.5652, -0.4540, -0.5555, -0.7963, -0.8398, -0.3428,\n",
       "           -0.7397, -0.5240, -0.4986, -0.5134, -0.3631, -7.9636, -1.0304, -2.2395,\n",
       "           -0.4884, -1.3321, -0.6454, -1.8018, -0.7135, -0.2307, -0.3432, -0.2779,\n",
       "           -1.3764, -0.4813, -0.1043, -0.4405, -0.2887, -0.4731, -0.4873, -0.4684,\n",
       "           -0.4141, -1.8579, -0.5047, -1.8889, -0.4941, -0.6789, -0.7784, -0.4295,\n",
       "           -0.8238, -1.3235, -0.4844, -1.2226, -1.0164, -0.9491, -0.2027, -0.6116,\n",
       "           -0.3604, -0.6660, -0.0955, -0.8047, -0.2817, -0.3042, -1.0451, -0.1472,\n",
       "           -0.3012, -0.5590, -1.7625, -1.5516, -0.9451, -0.9896, -1.1100, -0.5804,\n",
       "           -1.8391, -0.4087, -0.9272, -0.2360, -0.6335, -0.7148, -0.2214, -0.9059,\n",
       "           -0.3204, -1.2163, -1.9739, -0.9866, -1.4000, -0.4824, -0.2586, -0.3593,\n",
       "           -0.3982, -0.3181, -1.2824, -0.3501, -1.2851, -0.6792, -0.4075, -0.5435,\n",
       "           -1.4434, -0.2909, -0.8426, -0.3501, -0.7710, -1.0305, -0.1861, -1.1038,\n",
       "           -1.0661, -0.5210, -1.0693, -0.2874, -0.6392, -0.6094, -0.3139, -0.2193,\n",
       "           -0.4861, -0.1864, -2.3681, -0.1969, -0.9368, -0.4448, -0.2280, -1.2514,\n",
       "           -0.4807, -0.6300, -1.0274, -1.5416, -0.6364, -1.5720, -0.1350, -1.0773,\n",
       "           -0.4786, -0.5470, -0.2780, -1.4592, -1.5147, -0.2718, -0.3989, -1.1786,\n",
       "           -5.6605, -0.6782, -2.7737, -1.0909, -0.3743, -0.3561, -0.4240, -1.2310,\n",
       "           -0.3133, -0.4349, -1.4310, -1.6016, -0.4805, -0.8008, -0.7512, -0.2877,\n",
       "           -0.5148, -0.4711, -0.6996, -1.3709, -1.0947, -1.5876, -0.3010, -0.1859,\n",
       "           -0.3077, -1.3350, -1.4057, -0.1185, -0.6457, -0.5484, -0.3718, -0.7903,\n",
       "           -0.2159, -0.5029, -0.3659, -0.5846, -0.8556, -0.5323, -1.2446, -0.2851,\n",
       "           -0.1852, -0.3632, -0.8982, -0.2503, -0.3257, -0.6217, -0.6953, -0.3426,\n",
       "           -0.3257, -0.9198, -0.2291, -1.0095, -0.3689, -0.4651, -0.4876, -2.7514,\n",
       "           -0.7448, -0.6297, -2.7169, -0.3943, -0.5034, -1.3349, -2.5562, -0.9338,\n",
       "           -0.2612, -0.6003, -0.4439, -0.4820, -0.8912, -0.3756, -0.7066, -0.5753,\n",
       "           -0.2209, -1.5010, -0.5324, -1.9875, -0.3542, -0.5125, -0.9178, -1.5801,\n",
       "           -1.5894, -0.8675, -1.1146, -0.3769, -0.6137, -0.4370, -1.3927, -0.1124,\n",
       "           -0.5305, -0.5052, -0.3173, -0.9353, -1.4578, -0.9024, -1.0796, -3.0102,\n",
       "           -0.4995, -0.6243, -1.6973, -2.3352, -0.2923, -0.3427, -0.3270, -0.2292,\n",
       "           -0.2401, -0.2580, -0.3516, -0.7347, -1.5419, -1.9889, -0.8438, -1.2242,\n",
       "           -0.6512, -1.5894, -0.4474, -0.4638, -0.2553, -0.3232, -0.1668, -0.6258,\n",
       "           -0.4197, -0.4770, -0.8443, -0.2512, -1.7504, -0.2200, -0.2601, -1.0473,\n",
       "           -0.2973, -0.4281, -0.8199, -0.6475, -0.3883, -0.2688, -0.6729, -1.1893,\n",
       "           -0.5333, -0.5048, -0.4685, -1.1165, -0.6274, -1.0531, -0.5348, -0.3256,\n",
       "           -1.0486, -0.2577, -0.4963, -1.1818, -0.7122, -1.0641, -0.3667, -0.2346,\n",
       "           -1.6055, -0.3232, -0.5803, -1.1525, -0.6757, -0.8294, -0.5326, -0.8852,\n",
       "           -1.1454, -0.6513, -0.3256, -0.9447, -1.3319, -0.6531, -0.4486, -0.2615,\n",
       "           -0.2598, -1.8612, -0.2522, -0.5479, -2.7270, -0.3967, -0.7486, -0.4135,\n",
       "           -0.7493, -0.2708, -1.1226, -0.2304, -0.5228, -1.0226, -0.1345, -0.3662,\n",
       "           -1.2194, -0.3815, -2.3900, -0.2144, -0.8420, -0.5990, -0.5557, -0.4041,\n",
       "           -0.3085, -0.2752, -1.1025, -1.0163, -0.9182, -0.3687, -0.4307, -0.3515,\n",
       "           -0.2035, -0.9773, -0.3041, -0.2056, -1.0215, -0.4262, -1.5308, -0.2017,\n",
       "           -0.9948, -0.4359, -0.1639, -0.2581, -0.2112, -0.5469, -0.2423, -0.4166,\n",
       "           -0.1974, -0.4188, -1.2853, -0.6410, -1.0999, -0.7567, -0.2193, -0.4392,\n",
       "           -0.3416, -1.2746, -0.6347, -0.4996, -0.7261, -0.5513, -0.1447, -0.7168,\n",
       "           -0.6181, -0.8220, -0.2433, -0.9557, -1.2401, -0.3894, -2.1528, -0.4847,\n",
       "           -0.7075, -0.3311, -0.3308, -0.4909, -0.8226, -0.6020, -1.1303, -0.8283,\n",
       "           -0.6253, -0.6531, -0.1489, -1.2208, -1.2826, -0.7812, -0.9396, -0.7625,\n",
       "           -0.3568, -1.0110, -0.3803, -0.7811, -1.0401, -0.8480, -0.4753, -0.3381,\n",
       "           -1.5521, -0.2696, -0.3231, -0.6727, -0.5847, -0.9570, -0.2096, -0.3357,\n",
       "           -0.2451, -2.0308, -0.9591, -0.3590, -0.6698, -1.3760, -0.5604, -1.1839,\n",
       "           -0.8339, -0.8764, -2.4871, -0.5115, -0.3820, -0.9444, -0.5951, -0.3874,\n",
       "           -0.5762, -1.8213, -0.4294, -0.7905, -1.3811, -1.4166, -0.3771, -0.4682,\n",
       "           -1.1493, -0.6221, -0.7736, -1.2787, -1.1378, -0.5035, -0.1303, -0.6286,\n",
       "           -0.4474, -0.2353, -0.2934, -0.2574, -0.8762, -0.3148, -0.2991, -1.8232,\n",
       "           -0.3585, -0.7813, -0.6537, -0.8768, -0.3110, -0.3727, -0.6397, -0.4003,\n",
       "           -0.8919, -0.9401, -0.4841, -0.5640, -1.6129, -0.8372, -0.2773, -0.7794,\n",
       "           -0.3490, -0.6287, -0.8151, -0.8997, -0.2666, -0.5921, -0.6982, -0.3744,\n",
       "           -2.3226, -0.6079, -0.6253, -0.6974, -0.5282, -1.1625, -1.7611, -0.7869,\n",
       "           -0.5039, -0.3293, -0.3582, -1.4720, -0.6074, -2.2881, -0.8023, -0.7471,\n",
       "           -0.8859, -1.0997, -0.2882, -0.4881, -0.4064, -0.5736, -0.8907, -0.5401,\n",
       "           -0.8723, -2.3321, -1.1036, -0.4415, -0.5426, -0.3409, -0.5044, -0.0895,\n",
       "           -0.5289, -0.3195, -3.8515, -0.2909, -0.1892, -0.5424, -1.6855, -5.1748,\n",
       "           -2.0986, -1.8658, -0.4588, -0.9927, -0.6345, -1.1378, -1.1650, -0.3461,\n",
       "           -2.4460, -1.2644, -0.4604, -0.9225, -0.3087, -0.7637, -0.4937, -0.7179,\n",
       "           -0.6688, -0.8156, -0.2834, -0.4541, -0.7395, -0.3746, -0.4648, -0.2272,\n",
       "           -0.4260, -1.4599, -0.2006, -1.7395, -0.2527, -0.3871, -0.8647, -0.2821,\n",
       "           -0.5343, -0.3973, -0.5832, -0.2881, -0.6637, -0.6160, -0.4749, -0.6144,\n",
       "           -0.7736, -0.2140, -0.9468, -0.6271, -0.2452, -0.4329, -1.1070, -0.4217,\n",
       "           -0.3907, -0.9428, -1.0649, -1.4408, -0.5195, -0.3952, -0.4557, -1.5093],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 1.5972e-15, -4.3731e-03,  4.6361e-16,  ...,  5.9053e-06,\n",
       "             3.8055e-10, -9.9537e-09],\n",
       "           [-9.1411e-07,  1.0872e-01, -1.0446e-05,  ...,  2.4136e-04,\n",
       "            -4.5720e-04, -5.8232e-04],\n",
       "           [-3.8893e-09, -1.7974e-02, -5.6835e-07,  ..., -3.1187e-03,\n",
       "             7.3954e-04, -1.5978e-01],\n",
       "           ...,\n",
       "           [-4.8571e-07, -3.2482e-02, -6.4068e-07,  ..., -2.3852e-04,\n",
       "            -9.8281e-04, -7.5849e-05],\n",
       "           [-3.2764e-04,  1.6344e-02, -1.0281e-03,  ..., -5.5529e-03,\n",
       "            -2.1008e-03, -1.9422e-03],\n",
       "           [ 5.2099e-05, -1.3904e-02,  2.6202e-04,  ..., -1.6252e-02,\n",
       "            -7.5380e-03, -1.3477e-03]], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-0.1806,  0.2207,  0.2474,  0.0879,  0.0849, -0.1353, -0.2200, -0.1299,\n",
       "            0.0417, -0.0168], device='cuda:0', requires_grad=True)],\n",
       "  'lr': 2.0,\n",
       "  'momentum': 0.5,\n",
       "  'dampening': 0,\n",
       "  'weight_decay': 0,\n",
       "  'nesterov': False,\n",
       "  'maximize': False,\n",
       "  'foreach': None,\n",
       "  'differentiable': False,\n",
       "  'fused': None}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=initial_lr, momentum=initial_momentum)\n",
    "optimizer.param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b49aa612-c308-4b0c-815f-b4275e965e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, epochs):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=initial_lr, momentum=initial_momentum)\n",
    "    train_errors = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        if epoch < momentum_epochs:\n",
    "            momentum = initial_momentum + (final_momentum - initial_momentum) * epoch / momentum_epochs\n",
    "        else:\n",
    "            momentum = final_momentum\n",
    "        optimizer.param_groups[0]['momentum'] = momentum\n",
    "        \n",
    "        lr = initial_lr * (lr_decay ** epoch) * (1 - momentum)\n",
    "        optimizer.param_groups[0]['lr'] = lr\n",
    "        \n",
    "        model.train()\n",
    "        for data, target in tqdm(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            constrain_weights(model)\n",
    "        \n",
    "        #train_err,error_rate  = evaluate_model(model, train_loader)\n",
    "        #train_errors.append(error_rate)\n",
    "        #print(f\" Epoch {epoch+1}/{epochs}: Train Errors = {train_err} , Error rate = {error_rate}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83d6d4ba-ed1b-43f6-a6ec-073c03b213ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(test_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    errors = total - correct\n",
    "    error_rate = (errors / total) * 100\n",
    "    return errors, error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "af47a973-414a-4e71-a415-6708cdc5a703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ensemble(models, test_loader):\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(test_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = torch.zeros(data.size(0), 10).to(device)\n",
    "            for model in models:\n",
    "                outputs += model(data) / len(models)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    errors = total - correct\n",
    "    error_rate = (errors / total) * 100\n",
    "    return errors, error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "07fb31e2-9c16-46c2-8082-854e4d539adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnn_configs = [\n",
    "    [784, 800, 800, 10],\n",
    "    [784, 1200, 1200, 10],\n",
    "    [784, 1200, 1200, 1200, 10]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf2ae64c-8bff-444b-a021-d77cd228152d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training FNN with architecture: [784, 800, 800, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 938/938 [00:37<00:00, 25.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 1/50: Train Errors = 52624 , Error rate = 87.70666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 938/938 [00:36<00:00, 25.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 2/50: Train Errors = 53191 , Error rate = 88.65166666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 938/938 [00:37<00:00, 25.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 3/50: Train Errors = 53695 , Error rate = 89.49166666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 938/938 [00:35<00:00, 26.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 4/50: Train Errors = 53275 , Error rate = 88.79166666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 938/938 [00:33<00:00, 27.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 5/50: Train Errors = 52515 , Error rate = 87.52499999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 938/938 [00:33<00:00, 27.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 6/50: Train Errors = 52897 , Error rate = 88.16166666666668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 938/938 [00:23<00:00, 40.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 7/50: Train Errors = 52295 , Error rate = 87.15833333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 938/938 [00:21<00:00, 42.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 8/50: Train Errors = 53984 , Error rate = 89.97333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|████████████████████████████▉                                                   | 340/938 [00:09<00:16, 37.23it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining FNN with architecture: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m model = NN(config).to(device)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m model , error_list = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m errors, error_rate = evaluate_model(model, test_loader)\n\u001b[32m      7\u001b[39m fnn_results[\u001b[38;5;28mstr\u001b[39m(config)] = error_list\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, epochs)\u001b[39m\n\u001b[32m     23\u001b[39m     optimizer.step()\n\u001b[32m     24\u001b[39m     constrain_weights(model)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m train_err,error_rate  = \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m train_errors.append(error_rate)\n\u001b[32m     28\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: Train Errors = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_err\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m , Error rate = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mevaluate_model\u001b[39m\u001b[34m(model, test_loader)\u001b[39m\n\u001b[32m      4\u001b[39m total = \u001b[32m0\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\code\\ML\\git_repo_for_ml_learning\\python_envs\\pytch\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\code\\ML\\git_repo_for_ml_learning\\python_envs\\pytch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\code\\ML\\git_repo_for_ml_learning\\python_envs\\pytch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\code\\ML\\git_repo_for_ml_learning\\python_envs\\pytch\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\code\\ML\\git_repo_for_ml_learning\\python_envs\\pytch\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\code\\ML\\git_repo_for_ml_learning\\python_envs\\pytch\\Lib\\site-packages\\torchvision\\datasets\\mnist.py:146\u001b[39m, in \u001b[36mMNIST.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    143\u001b[39m img = Image.fromarray(img.numpy(), mode=\u001b[33m\"\u001b[39m\u001b[33mL\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     img = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.target_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    149\u001b[39m     target = \u001b[38;5;28mself\u001b[39m.target_transform(target)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\code\\ML\\git_repo_for_ml_learning\\python_envs\\pytch\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[39m, in \u001b[36mCompose.__call__\u001b[39m\u001b[34m(self, img)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         img = \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\code\\ML\\git_repo_for_ml_learning\\python_envs\\pytch\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[39m, in \u001b[36mToTensor.__call__\u001b[39m\u001b[34m(self, pic)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[32m    130\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    131\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    135\u001b[39m \u001b[33;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[32m    136\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\code\\ML\\git_repo_for_ml_learning\\python_envs\\pytch\\Lib\\site-packages\\torchvision\\transforms\\functional.py:172\u001b[39m, in \u001b[36mto_tensor\u001b[39m\u001b[34m(pic)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pic.mode == \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    171\u001b[39m     img = \u001b[32m255\u001b[39m * img\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m img = \u001b[43mimg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpic\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mF_pil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_image_num_channels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[38;5;66;03m# put it from HWC to CHW format\u001b[39;00m\n\u001b[32m    174\u001b[39m img = img.permute((\u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m)).contiguous()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "ffnn_results = {}\n",
    "for config in fnn_configs:\n",
    "    print(f\"Training FNN with architecture: {config}\")\n",
    "    model = NN(config).to(device)\n",
    "    model , error_list = train_model(model, train_loader, epochs)\n",
    "    errors, error_rate = evaluate_model(model, test_loader)\n",
    "    fnn_results[str(config)] = error_list\n",
    "    print(f\"FNN {config}: {errors} errors ({error_rate:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d4ca67-41b3-4754-b3d5-8d2fcc4ee311",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_models = [NN(fnn_configs[0]).to(device), NN(fnn_configs[1]).to(device), NN(fnn_configs[2]).to(device)]\n",
    "ensemble_names = [\"NN1\", \"NN2\", \"NN3\"]\n",
    "ensemble_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b9bab9b-122c-48c8-8625-cce986827cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training NN1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|████████████████████████████████████████████████████████████████████| 938/938 [00:27<00:00, 34.43it/s]\n",
      "Epoch 2/50: 100%|████████████████████████████████████████████████████████████████████| 938/938 [00:21<00:00, 42.87it/s]\n",
      "Epoch 3/50: 100%|████████████████████████████████████████████████████████████████████| 938/938 [00:21<00:00, 43.70it/s]\n",
      "Epoch 4/50: 100%|████████████████████████████████████████████████████████████████████| 938/938 [00:21<00:00, 43.24it/s]\n",
      "Epoch 5/50: 100%|████████████████████████████████████████████████████████████████████| 938/938 [00:21<00:00, 42.96it/s]\n",
      "Epoch 6/50: 100%|████████████████████████████████████████████████████████████████████| 938/938 [00:24<00:00, 38.29it/s]\n",
      "Epoch 7/50: 100%|████████████████████████████████████████████████████████████████████| 938/938 [00:23<00:00, 40.77it/s]\n",
      "Epoch 8/50: 100%|████████████████████████████████████████████████████████████████████| 938/938 [00:26<00:00, 35.82it/s]\n",
      "Epoch 9/50: 100%|████████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 42.20it/s]\n",
      "Epoch 10/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 42.48it/s]\n",
      "Epoch 11/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:21<00:00, 43.13it/s]\n",
      "Epoch 12/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:21<00:00, 43.08it/s]\n",
      "Epoch 13/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:24<00:00, 38.73it/s]\n",
      "Epoch 14/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:23<00:00, 39.32it/s]\n",
      "Epoch 15/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 41.37it/s]\n",
      "Epoch 16/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 42.61it/s]\n",
      "Epoch 17/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:24<00:00, 38.88it/s]\n",
      "Epoch 18/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 41.90it/s]\n",
      "Epoch 19/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 41.76it/s]\n",
      "Epoch 20/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:23<00:00, 39.33it/s]\n",
      "Epoch 21/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 41.28it/s]\n",
      "Epoch 22/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:23<00:00, 39.43it/s]\n",
      "Epoch 23/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 41.39it/s]\n",
      "Epoch 24/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:24<00:00, 38.14it/s]\n",
      "Epoch 25/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 42.55it/s]\n",
      "Epoch 26/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 42.48it/s]\n",
      "Epoch 27/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:23<00:00, 39.60it/s]\n",
      "Epoch 28/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:21<00:00, 44.10it/s]\n",
      "Epoch 29/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:21<00:00, 43.74it/s]\n",
      "Epoch 30/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 41.67it/s]\n",
      "Epoch 31/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 42.08it/s]\n",
      "Epoch 32/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:24<00:00, 38.41it/s]\n",
      "Epoch 33/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:24<00:00, 39.06it/s]\n",
      "Epoch 34/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:24<00:00, 37.57it/s]\n",
      "Epoch 35/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 41.35it/s]\n",
      "Epoch 36/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:24<00:00, 38.44it/s]\n",
      "Epoch 37/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 42.44it/s]\n",
      "Epoch 38/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:25<00:00, 37.26it/s]\n",
      "Epoch 39/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:23<00:00, 39.34it/s]\n",
      "Epoch 40/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 41.54it/s]\n",
      "Epoch 41/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 41.45it/s]\n",
      "Epoch 42/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:23<00:00, 39.65it/s]\n",
      "Epoch 43/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 42.13it/s]\n",
      "Epoch 44/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:24<00:00, 38.42it/s]\n",
      "Epoch 45/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:23<00:00, 40.18it/s]\n",
      "Epoch 46/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:23<00:00, 40.14it/s]\n",
      "Epoch 47/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:25<00:00, 37.26it/s]\n",
      "Epoch 48/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:23<00:00, 39.32it/s]\n",
      "Epoch 49/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:21<00:00, 44.05it/s]\n",
      "Epoch 50/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:20<00:00, 45.02it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 157/157 [00:01<00:00, 80.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN1: 9045 errors (90.45%)\n",
      "Training NN2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|████████████████████████████████████████████████████████████████████| 938/938 [00:20<00:00, 45.65it/s]\n",
      "Epoch 2/50: 100%|████████████████████████████████████████████████████████████████████| 938/938 [00:20<00:00, 45.68it/s]\n",
      "Epoch 3/50: 100%|████████████████████████████████████████████████████████████████████| 938/938 [00:20<00:00, 44.77it/s]\n",
      "Epoch 4/50: 100%|████████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 42.31it/s]\n",
      "Epoch 5/50: 100%|████████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 41.40it/s]\n",
      "Epoch 6/50: 100%|████████████████████████████████████████████████████████████████████| 938/938 [00:21<00:00, 43.20it/s]\n",
      "Epoch 7/50: 100%|████████████████████████████████████████████████████████████████████| 938/938 [00:23<00:00, 39.88it/s]\n",
      "Epoch 8/50: 100%|████████████████████████████████████████████████████████████████████| 938/938 [00:25<00:00, 37.47it/s]\n",
      "Epoch 9/50: 100%|████████████████████████████████████████████████████████████████████| 938/938 [00:24<00:00, 38.65it/s]\n",
      "Epoch 10/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:24<00:00, 39.00it/s]\n",
      "Epoch 11/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 41.83it/s]\n",
      "Epoch 12/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 42.48it/s]\n",
      "Epoch 13/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 41.62it/s]\n",
      "Epoch 14/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 41.45it/s]\n",
      "Epoch 15/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 42.56it/s]\n",
      "Epoch 16/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 42.49it/s]\n",
      "Epoch 17/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:23<00:00, 40.75it/s]\n",
      "Epoch 18/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 41.53it/s]\n",
      "Epoch 19/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 40.89it/s]\n",
      "Epoch 20/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:23<00:00, 39.45it/s]\n",
      "Epoch 21/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 41.57it/s]\n",
      "Epoch 22/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 42.20it/s]\n",
      "Epoch 23/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:21<00:00, 43.43it/s]\n",
      "Epoch 24/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:21<00:00, 43.21it/s]\n",
      "Epoch 25/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 41.48it/s]\n",
      "Epoch 26/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:21<00:00, 42.97it/s]\n",
      "Epoch 27/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 42.57it/s]\n",
      "Epoch 28/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 41.28it/s]\n",
      "Epoch 29/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:24<00:00, 38.94it/s]\n",
      "Epoch 30/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:23<00:00, 40.57it/s]\n",
      "Epoch 31/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 42.16it/s]\n",
      "Epoch 32/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 41.85it/s]\n",
      "Epoch 33/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:23<00:00, 40.72it/s]\n",
      "Epoch 34/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:23<00:00, 40.69it/s]\n",
      "Epoch 35/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:23<00:00, 40.76it/s]\n",
      "Epoch 36/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:23<00:00, 39.65it/s]\n",
      "Epoch 37/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:21<00:00, 44.27it/s]\n",
      "Epoch 38/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:20<00:00, 45.75it/s]\n",
      "Epoch 39/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:20<00:00, 45.39it/s]\n",
      "Epoch 40/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:20<00:00, 45.88it/s]\n",
      "Epoch 41/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:20<00:00, 45.30it/s]\n",
      "Epoch 42/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:21<00:00, 44.14it/s]\n",
      "Epoch 43/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:20<00:00, 45.43it/s]\n",
      "Epoch 44/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:20<00:00, 45.39it/s]\n",
      "Epoch 45/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 42.43it/s]\n",
      "Epoch 46/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 41.48it/s]\n",
      "Epoch 47/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 42.45it/s]\n",
      "Epoch 48/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:21<00:00, 42.95it/s]\n",
      "Epoch 49/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:20<00:00, 46.87it/s]\n",
      "Epoch 50/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:21<00:00, 43.62it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 157/157 [00:02<00:00, 70.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN2: 8972 errors (89.72%)\n",
      "Training NN3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|████████████████████████████████████████████████████████████████████| 938/938 [00:23<00:00, 39.48it/s]\n",
      "Epoch 2/50: 100%|████████████████████████████████████████████████████████████████████| 938/938 [00:23<00:00, 40.03it/s]\n",
      "Epoch 3/50: 100%|████████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 41.80it/s]\n",
      "Epoch 4/50: 100%|████████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 40.90it/s]\n",
      "Epoch 5/50: 100%|████████████████████████████████████████████████████████████████████| 938/938 [00:24<00:00, 37.97it/s]\n",
      "Epoch 6/50: 100%|████████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 40.91it/s]\n",
      "Epoch 7/50: 100%|████████████████████████████████████████████████████████████████████| 938/938 [00:23<00:00, 39.72it/s]\n",
      "Epoch 8/50: 100%|████████████████████████████████████████████████████████████████████| 938/938 [00:24<00:00, 38.16it/s]\n",
      "Epoch 9/50: 100%|████████████████████████████████████████████████████████████████████| 938/938 [00:24<00:00, 38.91it/s]\n",
      "Epoch 10/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:23<00:00, 39.10it/s]\n",
      "Epoch 11/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:24<00:00, 37.99it/s]\n",
      "Epoch 12/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:25<00:00, 37.50it/s]\n",
      "Epoch 13/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:25<00:00, 36.56it/s]\n",
      "Epoch 14/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:24<00:00, 38.11it/s]\n",
      "Epoch 15/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:23<00:00, 40.00it/s]\n",
      "Epoch 16/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 42.35it/s]\n",
      "Epoch 17/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 41.81it/s]\n",
      "Epoch 18/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 42.04it/s]\n",
      "Epoch 19/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:21<00:00, 43.06it/s]\n",
      "Epoch 20/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 41.66it/s]\n",
      "Epoch 21/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:21<00:00, 44.05it/s]\n",
      "Epoch 22/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:20<00:00, 44.88it/s]\n",
      "Epoch 23/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:21<00:00, 44.55it/s]\n",
      "Epoch 24/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:20<00:00, 45.03it/s]\n",
      "Epoch 25/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:21<00:00, 44.12it/s]\n",
      "Epoch 26/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:21<00:00, 44.38it/s]\n",
      "Epoch 27/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:21<00:00, 43.62it/s]\n",
      "Epoch 28/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:21<00:00, 44.50it/s]\n",
      "Epoch 29/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 41.78it/s]\n",
      "Epoch 30/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [06:56<00:00,  2.25it/s]\n",
      "Epoch 31/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 41.50it/s]\n",
      "Epoch 32/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 41.02it/s]\n",
      "Epoch 33/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:23<00:00, 39.21it/s]\n",
      "Epoch 34/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 41.21it/s]\n",
      "Epoch 35/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:23<00:00, 39.75it/s]\n",
      "Epoch 36/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:25<00:00, 36.24it/s]\n",
      "Epoch 37/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:25<00:00, 37.19it/s]\n",
      "Epoch 38/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:25<00:00, 37.47it/s]\n",
      "Epoch 39/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:23<00:00, 40.64it/s]\n",
      "Epoch 40/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:22<00:00, 41.76it/s]\n",
      "Epoch 41/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:21<00:00, 43.75it/s]\n",
      "Epoch 42/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:20<00:00, 44.96it/s]\n",
      "Epoch 43/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:21<00:00, 43.07it/s]\n",
      "Epoch 44/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:21<00:00, 43.25it/s]\n",
      "Epoch 45/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:20<00:00, 45.26it/s]\n",
      "Epoch 46/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:21<00:00, 44.55it/s]\n",
      "Epoch 47/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:21<00:00, 44.45it/s]\n",
      "Epoch 48/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:28<00:00, 33.17it/s]\n",
      "Epoch 49/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:41<00:00, 22.53it/s]\n",
      "Epoch 50/50: 100%|███████████████████████████████████████████████████████████████████| 938/938 [00:40<00:00, 23.25it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 157/157 [00:03<00:00, 42.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN3: 8865 errors (88.65%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for name, model in zip(ensemble_names, ensemble_models):\n",
    "    print(f\"Training {name}\")\n",
    "    model = train_model(model, train_loader, epochs)\n",
    "    errors, error_rate = evaluate_model(model, test_loader)\n",
    "    ensemble_results[name] = (errors, error_rate)\n",
    "    print(f\"{name}: {errors} errors ({error_rate:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70bc0327-fef0-494a-94fd-6077f70d9047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffnn_results.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68ec6881-a83e-4bd2-aff5-b03ef2113bef",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (50,) and (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m     plt.plot(\u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, epochs+\u001b[32m1\u001b[39m), test_errors, label=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFNN \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Test\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, (train_errors, test_errors) \u001b[38;5;129;01min\u001b[39;00m ensemble_results.items():\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     \u001b[43mplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_errors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m Train\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinestyle\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m--\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     plt.plot(\u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, epochs+\u001b[32m1\u001b[39m), test_errors, label=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Test\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m plt.plot(\u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, epochs+\u001b[32m1\u001b[39m), ensemble_train_errors, label=\u001b[33m\"\u001b[39m\u001b[33mCNN Ensemble Train\u001b[39m\u001b[33m\"\u001b[39m, linestyle=\u001b[33m'\u001b[39m\u001b[33m--\u001b[39m\u001b[33m'\u001b[39m, linewidth=\u001b[32m2\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\code\\ML\\git_repo_for_ml_learning\\python_envs\\pytch\\Lib\\site-packages\\matplotlib\\pyplot.py:3838\u001b[39m, in \u001b[36mplot\u001b[39m\u001b[34m(scalex, scaley, data, *args, **kwargs)\u001b[39m\n\u001b[32m   3830\u001b[39m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes.plot)\n\u001b[32m   3831\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mplot\u001b[39m(\n\u001b[32m   3832\u001b[39m     *args: \u001b[38;5;28mfloat\u001b[39m | ArrayLike | \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3836\u001b[39m     **kwargs,\n\u001b[32m   3837\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[32m-> \u001b[39m\u001b[32m3838\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3839\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3840\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscalex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3841\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscaley\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3842\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3843\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3844\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\code\\ML\\git_repo_for_ml_learning\\python_envs\\pytch\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:1777\u001b[39m, in \u001b[36mAxes.plot\u001b[39m\u001b[34m(self, scalex, scaley, data, *args, **kwargs)\u001b[39m\n\u001b[32m   1534\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1535\u001b[39m \u001b[33;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[32m   1536\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1774\u001b[39m \u001b[33;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1776\u001b[39m kwargs = cbook.normalize_kwargs(kwargs, mlines.Line2D)\n\u001b[32m-> \u001b[39m\u001b[32m1777\u001b[39m lines = [*\u001b[38;5;28mself\u001b[39m._get_lines(\u001b[38;5;28mself\u001b[39m, *args, data=data, **kwargs)]\n\u001b[32m   1778\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[32m   1779\u001b[39m     \u001b[38;5;28mself\u001b[39m.add_line(line)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\code\\ML\\git_repo_for_ml_learning\\python_envs\\pytch\\Lib\\site-packages\\matplotlib\\axes\\_base.py:297\u001b[39m, in \u001b[36m_process_plot_var_args.__call__\u001b[39m\u001b[34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m    295\u001b[39m     this += args[\u001b[32m0\u001b[39m],\n\u001b[32m    296\u001b[39m     args = args[\u001b[32m1\u001b[39m:]\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_kwargs\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\code\\ML\\git_repo_for_ml_learning\\python_envs\\pytch\\Lib\\site-packages\\matplotlib\\axes\\_base.py:494\u001b[39m, in \u001b[36m_process_plot_var_args._plot_args\u001b[39m\u001b[34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[39m\n\u001b[32m    491\u001b[39m     axes.yaxis.update_units(y)\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x.shape[\u001b[32m0\u001b[39m] != y.shape[\u001b[32m0\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mx and y must have same first dimension, but \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    495\u001b[39m                      \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    496\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x.ndim > \u001b[32m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y.ndim > \u001b[32m2\u001b[39m:\n\u001b[32m    497\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mx and y can be no greater than 2D, but have \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    498\u001b[39m                      \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: x and y must have same first dimension, but have shapes (50,) and (1,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 8))\n",
    "for config, (train_errors, test_errors) in ffnn_results.items():\n",
    "    plt.plot(range(1, epochs+1), train_errors, label=f\"FNN {config} Train\", linestyle='--')\n",
    "    plt.plot(range(1, epochs+1), test_errors, label=f\"FNN {config} Test\")\n",
    "for name, (train_errors, test_errors) in ensemble_results.items():\n",
    "    plt.plot(range(1, epochs+1), train_errors, label=f\"{name} Train\", linestyle='--')\n",
    "    plt.plot(range(1, epochs+1), test_errors, label=f\"{name} Test\")\n",
    "plt.plot(range(1, epochs+1), ensemble_train_errors, label=\"CNN Ensemble Train\", linestyle='--', linewidth=2)\n",
    "plt.plot(range(1, epochs+1), ensemble_test_errors, label=\"CNN Ensemble Test\", linewidth=2)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Errors\")\n",
    "plt.title(\"Train and Test Errors per Epoch for FNNs and CNN Ensemble on MNIST\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('mnist_errors_per_epoch.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d888859a-131e-4c96-a7bd-2551f63ea081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate ensemble\n",
    "print(\"Evaluating NN ensemble\")\n",
    "ensemble_errors, ensemble_error_rate = evaluate_ensemble(ensemble_models, test_loader)\n",
    "print(f\"CNN Ensemble: {ensemble_errors} errors ({ensemble_error_rate:.2f}%)\")\n",
    "\n",
    "# Print comparison\n",
    "print(\"\\n=== Results Comparison ===\")\n",
    "print(\"NN Models:\")\n",
    "for config, (errors, error_rate) in ffnn_results.items():\n",
    "    print(f\"FNN {config}: {errors} errors ({error_rate:.2f}%)\")\n",
    "print(\"Individual NNs:\")\n",
    "for name, (errors, error_rate) in cnn_results.items():\n",
    "    print(f\"{name}: {errors} errors ({error_rate:.2f}%)\")\n",
    "print(f\"CNN Ensemble: {ensemble_errors} errors ({ensemble_error_rate:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e48116a-2eff-4630-8e95-09aeac7b6bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
